---
name: Ansible Tests

# Cancel in-progress runs when a new workflow is triggered
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run comprehensive tests weekly on Sundays at 3:00 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      test_level:
        description: |
          Test level to run:
          - standard: Basic lint/syntax tests only (~5 min)
          - comprehensive: Full test suite including all 14 test categories (~30 min)
          - critical-gaps-only: Focus on critical gap tests and security validation (~10 min)
        required: false
        default: 'standard'
        type: choice
        options:
        - 'standard'
        - 'comprehensive'
        - 'critical-gaps-only'

permissions:
  contents: read
  issues: read
  checks: read
  pull-requests: read

jobs:
  lint-and-syntax:
    name: Lint and Syntax Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.13.7"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run lint and syntax tests
        uses: ./.github/actions/lint-and-syntax
        with:
          python-version: ${{ matrix.python-version }}

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run unit tests
        uses: ./.github/actions/unit-tests

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run integration tests
        uses: ./.github/actions/integration-tests

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run security scan
        uses: ./.github/actions/security-scan

  mock-device-tests:
    name: Mock Device Framework Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run mock device tests
        uses: ./.github/actions/mock-device-tests

  molecule-tests:
    name: Molecule Tests
    runs-on: ubuntu-latest
    # Run molecule tests for multiple triggers:
    # - Push to main branch (production changes validation)
    # - Pull requests to main (pre-merge testing)
    # - Manual workflow dispatch (on-demand testing)
    # - Scheduled runs (automated periodic validation)
    if: |
      (github.event_name == 'push' && github.ref == 'refs/heads/main') ||
      (github.event_name == 'pull_request' && github.base_ref == 'main') ||
      github.event_name == 'workflow_dispatch' ||
      github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13.7'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('ansible-content/collections/requirements.yml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install --upgrade ansible molecule molecule-plugins[docker] docker
          # Clear any existing collections to avoid conflicts
          rm -rf ~/.ansible/collections
          # Install collections to user directory
          # Install collections with proper certificate validation
          # Note: --force used to overwrite existing collections for clean test environment
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force --collections-path ~/.ansible/collections

      - name: Validate test environment
        run: |
          echo "üîç Validating test environment setup..."
          # Verify Ansible installation
          ansible --version
          # Verify Python packages
          python -c "import ansible, molecule, docker; print('‚úÖ Required packages installed')"
          # Verify collections installation
          ansible-galaxy collection list | grep -E "(cisco|fortinet|community)" || echo "‚ö†Ô∏è Some collections may be missing"
          # Verify Docker availability
          docker info >/dev/null 2>&1 && echo "‚úÖ Docker available" || echo "‚ùå Docker not available"
          # Check test directory structure
          test -d tests/molecule-tests && echo "‚úÖ Molecule test directory found" || echo "‚ùå Molecule test directory missing"
          echo "üéØ Environment validation complete"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Run molecule tests for network upgrade
        run: |
          cd tests/molecule-tests
          # Retry mechanism for flaky molecule tests
          for attempt in 1 2 3; do
            echo "üîÑ Molecule test attempt $attempt/3"
            if molecule test -s network-upgrade-test; then
              echo "‚úÖ Molecule network upgrade tests passed on attempt $attempt"
              break
            elif [ $attempt -eq 3 ]; then
              echo "‚ùå Molecule network upgrade tests failed after 3 attempts"
              exit 1
            else
              echo "‚ö†Ô∏è Attempt $attempt failed, retrying in 30 seconds..."
              sleep 30
            fi
          done
        env:
          MOLECULE_NO_LOG: false
          MOLECULE_VERBOSITY: 1

      - name: Run default molecule tests
        run: |
          cd tests/molecule-tests
          # Retry mechanism for flaky molecule tests
          for attempt in 1 2 3; do
            echo "üîÑ Default molecule test attempt $attempt/3"
            if molecule test -s default; then
              echo "‚úÖ Default molecule tests passed on attempt $attempt"
              break
            elif [ $attempt -eq 3 ]; then
              echo "‚ùå Default molecule tests failed after 3 attempts"
              exit 1
            else
              echo "‚ö†Ô∏è Attempt $attempt failed, retrying in 30 seconds..."
              sleep 30
            fi
          done
        env:
          MOLECULE_NO_LOG: false

  critical-gap-tests:
    name: Critical Gap Test Suite
    runs-on: ubuntu-latest
    # Run critical gap tests for:
    # - Scheduled weekly runs (automatic comprehensive validation)
    # - Manual dispatch with 'critical-gaps-only' test level
    # - Manual dispatch with 'comprehensive' test level
    if: |
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' &&
       (inputs.test_level == 'critical-gaps-only' || inputs.test_level == 'comprehensive'))
    strategy:
      matrix:
        python-version: ["3.13.7"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('ansible-content/collections/requirements.yml') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade ansible psutil
          pip install yamllint ansible-lint

      - name: Install Ansible collections
        run: |
          # Install collections with proper certificate validation
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force

      - name: Create reports directory
        run: mkdir -p tests/reports

      - name: Run Critical Gap Test Suite
        run: |
          chmod +x tests/critical-gaps/run-all-critical-gap-tests.sh
          echo "üöÄ Starting Critical Gap Test Suite (estimated 10 minutes)"
          echo "üìä Progress will be reported every 2 minutes..."

          # Run with progress monitoring and timeout protection
          (
            sleep 120 && echo "‚è±Ô∏è 2 minutes elapsed - tests still running..."
            sleep 120 && echo "‚è±Ô∏è 4 minutes elapsed - continuing..."
            sleep 120 && echo "‚è±Ô∏è 6 minutes elapsed - nearing completion..."
            sleep 120 && echo "‚è±Ô∏è 8 minutes elapsed - final phase..."
          ) &
          PROGRESS_PID=$!

          if ! timeout 600 tests/critical-gaps/run-all-critical-gap-tests.sh; then
            kill $PROGRESS_PID 2>/dev/null || true
            echo "‚ùå Critical gap tests failed or timed out after 10 minutes"
            exit 1
          fi

          kill $PROGRESS_PID 2>/dev/null || true
          echo "‚úÖ Critical gap tests completed successfully"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: critical-gap-tests-py${{ matrix.python-version }}-${{ github.run_number }}-${{ github.sha }}
          path: |
            tests/reports/critical-gap-*.json
            tests/reports/critical-gap-*.log
            tests/reports/*-coverage-*.json
            tests/reports/test-summary-*.txt
          retention-days: 30
          if-no-files-found: warn

      - name: Display test summary
        if: always()
        run: |
          echo "=== CRITICAL GAP TEST SUMMARY ==="
          if [ -f tests/reports/critical-gap-test-summary-*.json ]; then
            latest_summary=$(ls -t tests/reports/critical-gap-test-summary-*.json | head -1)
            echo "üìä Latest test summary: $latest_summary"

            # Extract key metrics using jq if available
            if command -v jq &> /dev/null; then
              echo "üìà Success Rate: $(jq -r '.test_execution_summary.success_rate_percent' "$latest_summary")%"
              echo "‚úÖ Passed Tests: $(jq -r '.test_execution_summary.passed_tests' "$latest_summary")"
              echo "‚ùå Failed Tests: $(jq -r '.test_execution_summary.failed_tests' "$latest_summary")"
              echo "üí∞ Business Risk Addressed: $(jq -r '.business_impact.total_risk_addressed' "$latest_summary")"
              echo "üöÄ Production Readiness: $(jq -r '.business_impact.production_readiness' "$latest_summary")"
            else
              echo "üìÑ Raw summary:"
              cat "$latest_summary"
            fi
          else
            echo "‚ö†Ô∏è No test summary found - tests may not have completed successfully"
            ls -la tests/reports/ || echo "Reports directory not found"
          fi

  comprehensive-test-suite:
    name: Comprehensive Test Suite (All 14 Tests)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Run comprehensive test suite for:
    # - Scheduled weekly runs (full system validation)
    # - Manual dispatch with 'comprehensive' test level (on-demand full testing)
    if: |
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && inputs.test_level == 'comprehensive')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13.7'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-comprehensive-${{ hashFiles('ansible-content/collections/requirements.yml') }}
          restore-keys: |
            ${{ runner.os }}-pip-comprehensive-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade ansible psutil
          pip install yamllint ansible-lint

      - name: Install Ansible collections
        run: |
          # Install collections with proper certificate validation
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force

      - name: Create results directory
        run: mkdir -p tests/results

      - name: Run comprehensive test suite
        run: |
          cd tests
          chmod +x run-all-tests.sh
          echo "üöÄ Starting Comprehensive Test Suite - All 14 Test Categories (estimated 30 minutes)"
          echo "üìä Progress will be reported every 5 minutes..."

          # Run with progress monitoring
          (
            sleep 300 && echo "‚è±Ô∏è 5 minutes elapsed - syntax and lint tests complete"
            sleep 300 && echo "‚è±Ô∏è 10 minutes elapsed - unit tests in progress"
            sleep 300 && echo "‚è±Ô∏è 15 minutes elapsed - integration tests running"
            sleep 300 && echo "‚è±Ô∏è 20 minutes elapsed - vendor tests executing"
            sleep 300 && echo "‚è±Ô∏è 25 minutes elapsed - final validation phase"
          ) &
          PROGRESS_PID=$!

          # Run comprehensive tests with proper error handling
          if ! ./run-all-tests.sh; then
            kill $PROGRESS_PID 2>/dev/null || true
            echo "‚ùå Comprehensive test suite failed"
            echo "üìã Checking for test result summaries..."
            if [ -f results/test_report_*.txt ]; then
              echo "üìä Test report summary (last 20 lines):"
              tail -20 results/test_report_*.txt
            fi
            # Display failed test count if available
            if [ -f results/test_summary.txt ]; then
              echo "üìà Test summary:"
              cat results/test_summary.txt
            fi
            exit 1
          fi

          kill $PROGRESS_PID 2>/dev/null || true
          echo "‚úÖ Comprehensive test suite completed successfully - All 14 categories passed"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: comprehensive-tests-all14-${{ github.run_number }}-${{ github.sha }}
          path: |
            tests/results/test_report_*.txt
            tests/results/*_*.log
            tests/results/test_summary.txt
            tests/results/performance_*.json
            tests/results/coverage_*.html
          retention-days: 30
          if-no-files-found: warn

      - name: Generate test summary report
        if: always()
        run: |
          echo "üìä ====================" >> $GITHUB_STEP_SUMMARY
          echo "üìä COMPREHENSIVE TEST SUMMARY" >> $GITHUB_STEP_SUMMARY
          echo "üìä ====================" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f tests/results/test_summary.txt ]; then
            echo "### üìà Test Results" >> $GITHUB_STEP_SUMMARY
            cat tests/results/test_summary.txt >> $GITHUB_STEP_SUMMARY
          else
            echo "### ‚ö†Ô∏è Test Summary Not Available" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìã Test Categories Executed" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Syntax & Lint validation" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Unit tests (all platforms)" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Integration tests" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Vendor-specific tests" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Security validation" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Performance benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Total: 14 test categories completed**" >> $GITHUB_STEP_SUMMARY

      - name: Fail if any tests failed
        run: |
          # Check if comprehensive tests passed by checking exit status from previous steps
          if [ -f tests/results/test_summary.txt ]; then
            if grep -q "FAILED\|ERROR" tests/results/test_summary.txt; then
              echo "‚ùå Some tests failed - check test summary for details"
              exit 1
            fi
          fi
          echo "‚úÖ All comprehensive tests passed successfully"
          if grep -q "Passed: 14" tests/results/test_report_*.txt && grep -q "Failed: 0" tests/results/test_report_*.txt; then
            echo "‚úÖ All 14 test suites passed successfully"
          else
            echo "‚ùå Comprehensive test suite failed"
            echo "Test report contents:"
            cat tests/results/test_report_*.txt || echo "No test report found"
            exit 1
          fi

  call-container-build:
    name: Build Container Image
    needs: [lint-and-syntax, unit-tests, integration-tests, security-scan, mock-device-tests]
    # Also include conditional dependencies if they ran
    if: |
      github.event_name == 'push' && github.ref == 'refs/heads/main' &&
      (always() && !failure() && !cancelled())
    uses: ./.github/workflows/build-container.yml
    with:
      push_image: true
      build_type: 'fast-x64'
    secrets: inherit