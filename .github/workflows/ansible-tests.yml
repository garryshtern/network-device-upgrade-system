---
name: Ansible Tests

# Cancel in-progress runs when a new workflow is triggered
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

'on':
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run comprehensive tests weekly on Sundays at 3:00 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Test level to run'
        required: false
        default: 'standard'
        type: choice
        options:
        - 'standard'
        - 'comprehensive'
        - 'critical-gaps-only'

permissions:
  contents: write
  issues: read
  checks: read
  pull-requests: read
  packages: write

jobs:
  lint-and-syntax:
    name: Lint and Syntax Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.13.7"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Ansible Environment
        uses: ./.github/actions/setup-ansible
        with:
          python-version: ${{ matrix.python-version }}
          cache-key-suffix: 'lint-syntax'

      - name: Run YAML syntax validation
        run: |
          python3 tests/validation-scripts/yaml-validator.py --ansible-only

      - name: Run yamllint
        run: |
          yamllint ansible-content/
        continue-on-error: true

      - name: Run ansible-lint
        run: |
          ansible-lint ansible-content/playbooks/ ansible-content/roles/
        continue-on-error: true

      - name: Test playbook syntax
        run: |
          ansible-playbook --syntax-check \
            ansible-content/playbooks/main-upgrade-workflow.yml

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13.7'

      - name: Install Ansible
        run: |
          pip install --upgrade ansible
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force --ignore-certs

      - name: Run variable validation tests
        run: |
          ansible-playbook tests/unit-tests/variable-validation.yml

      - name: Run template rendering tests
        run: |
          ansible-playbook tests/unit-tests/template-rendering.yml

      - name: Run workflow logic tests
        run: |
          ansible-playbook tests/unit-tests/workflow-logic.yml

      - name: Run error handling tests
        run: |
          ansible-playbook tests/unit-tests/error-handling.yml

      - name: Run authentication validation tests
        run: |
          ansible-playbook tests/unit-tests/authentication-validation.yml

      - name: Run mock authentication validation tests
        run: |
          ansible-playbook tests/unit-tests/mock-authentication-validation.yml

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13.7'

      - name: Install Ansible
        run: |
          pip install --upgrade ansible
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force --ignore-certs

      - name: Run check mode tests
        run: |
          ANSIBLE_ROLES_PATH=ansible-content/roles \
          ANSIBLE_CONFIG=ansible-content/ansible.cfg \
          ansible-playbook -i tests/mock-inventories/all-platforms.yml \
            --check --diff tests/integration-tests/check-mode-tests.yml

      - name: Test main workflow syntax validation
        run: |
          ANSIBLE_ROLES_PATH=ansible-content/roles \
          ANSIBLE_CONFIG=ansible-content/ansible.cfg \
          ansible-playbook --syntax-check \
            ansible-content/playbooks/main-upgrade-workflow.yml

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run security scan for secrets
        run: |
          # Check for potential secrets in code
          grep -r "password\|secret\|key\|token" ansible-content/ \
            --include="*.yml" --include="*.yaml" || true
          echo "Security scan completed"

      - name: Check for hardcoded IPs
        run: |
          # Check for hardcoded IP addresses (except test/mock IPs)
          grep -r "192\.168\|10\.\|172\." ansible-content/ \
            --include="*.yml" --include="*.yaml" | \
            grep -v "127.0.0" || true
          echo "IP address scan completed"

  mock-device-tests:
    name: Mock Device Framework Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13.7'

      - name: Install dependencies
        run: |
          pip install --upgrade ansible paramiko psutil
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force --ignore-certs

      - name: Test mock device engine
        run: |
          cd tests/mock-devices
          python3 -c "
          from mock_device_engine import MockDeviceManager
          manager = MockDeviceManager()
          # Test each platform
          for platform in ['cisco_nxos', 'cisco_iosxe', 'fortios', 'opengear', 'metamako_mos']:
              device_id = manager.create_device(platform, f'test-{platform}')
              device = manager.devices[device_id]
              response = device.process_command('show version')
              assert 'status' in response, f'{platform} device failed basic command test'
              print(f'{platform}: OK')
          print('All mock devices functional')
          "

      - name: Run basic error simulation tests
        run: |
          # Run a subset of error simulation tests for PR validation
          ansible-playbook tests/error-scenarios/network_error_tests.yml \
            --extra-vars "test_subset=basic" || echo "Basic error tests completed"

  molecule-tests:
    name: Molecule Tests
    runs-on: ubuntu-latest
    # Run molecule tests only for main branch pushes, PRs to main, or manual triggers
    if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || (github.event_name == 'pull_request' && github.base_ref == 'main') || github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13.7'

      - name: Install dependencies
        run: |
          pip install --upgrade ansible molecule molecule-plugins[docker] docker
          # Clear any existing collections to avoid conflicts
          rm -rf ~/.ansible/collections
          # Install collections to user directory
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force --ignore-certs --collections-path ~/.ansible/collections

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Run molecule tests for network upgrade
        run: |
          cd tests/molecule-tests
          molecule test -s network-upgrade-test
        env:
          MOLECULE_NO_LOG: false
          MOLECULE_VERBOSITY: 1

      - name: Run default molecule tests  
        run: |
          cd tests/molecule-tests
          molecule test -s default
        env:
          MOLECULE_NO_LOG: false

  critical-gap-tests:
    name: Critical Gap Test Suite
    runs-on: ubuntu-latest
    # Only run on schedule, manual trigger with critical-gaps-only, or manual comprehensive
    if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && (inputs.test_level == 'critical-gaps-only' || inputs.test_level == 'comprehensive'))
    strategy:
      matrix:
        python-version: ["3.13.7"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade ansible psutil
          pip install yamllint ansible-lint

      - name: Install Ansible collections
        run: |
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force --ignore-certs

      - name: Create reports directory
        run: mkdir -p tests/reports

      - name: Run Critical Gap Test Suite
        run: |
          chmod +x tests/critical-gaps/run-all-critical-gap-tests.sh
          # Set timeout to prevent infinite execution
          timeout 600 tests/critical-gaps/run-all-critical-gap-tests.sh || true

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: critical-gap-test-results-${{ matrix.python-version }}
          path: |
            tests/reports/critical-gap-*.json
            tests/reports/critical-gap-*.log
            tests/reports/*-coverage-*.json
          retention-days: 30

      - name: Display test summary
        if: always()
        run: |
          echo "=== CRITICAL GAP TEST SUMMARY ==="
          if [ -f tests/reports/critical-gap-test-summary-*.json ]; then
            latest_summary=$(ls -t tests/reports/critical-gap-test-summary-*.json | head -1)
            echo "üìä Latest test summary: $latest_summary"

            # Extract key metrics using jq if available
            if command -v jq &> /dev/null; then
              echo "üìà Success Rate: $(jq -r '.test_execution_summary.success_rate_percent' "$latest_summary")%"
              echo "‚úÖ Passed Tests: $(jq -r '.test_execution_summary.passed_tests' "$latest_summary")"
              echo "‚ùå Failed Tests: $(jq -r '.test_execution_summary.failed_tests' "$latest_summary")"
              echo "üí∞ Business Risk Addressed: $(jq -r '.business_impact.total_risk_addressed' "$latest_summary")"
              echo "üöÄ Production Readiness: $(jq -r '.business_impact.production_readiness' "$latest_summary")"
            else
              echo "üìÑ Raw summary:"
              cat "$latest_summary"
            fi
          else
            echo "‚ö†Ô∏è No test summary found - tests may not have completed successfully"
            ls -la tests/reports/ || echo "Reports directory not found"
          fi

  comprehensive-test-suite:
    name: Comprehensive Test Suite (All 14 Tests)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Only run on schedule or manual trigger with comprehensive level
    if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && inputs.test_level == 'comprehensive')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13.7'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade ansible psutil
          pip install yamllint ansible-lint

      - name: Install Ansible collections
        run: |
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force --ignore-certs

      - name: Create results directory
        run: mkdir -p tests/results

      - name: Run comprehensive test suite
        run: |
          cd tests
          chmod +x run-all-tests.sh
          ./run-all-tests.sh

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: comprehensive-test-results-${{ github.run_number }}
          path: |
            tests/results/test_report_*.txt
            tests/results/*_*.log
          retention-days: 30

      - name: Fail if any tests failed
        run: |
          # Check if comprehensive tests passed by checking passed count and success rate
          if grep -q "Passed: 14" tests/results/test_report_*.txt && grep -q "Failed: 0" tests/results/test_report_*.txt; then
            echo "‚úÖ All 14 test suites passed successfully"
          else
            echo "‚ùå Comprehensive test suite failed"
            echo "Test report contents:"
            cat tests/results/test_report_*.txt || echo "No test report found"
            exit 1
          fi

  podman-tests:
    name: Podman 4.9.4 Testing
    runs-on: ubuntu-latest
    # Run Podman tests only on schedule, main push, or manual trigger
    if: github.event_name == 'schedule' || (github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'workflow_dispatch'
    strategy:
      matrix:
        python-version: ["3.13.7"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install Podman 4.9.4
        run: |
          echo "Installing Podman 4.9.4..."
          sudo apt-get update

          # Install dependencies
          sudo apt-get install -y curl wget gpg lsb-release

          # Use Ubuntu 22.04 repository for Ubuntu 24.04 compatibility
          # or fallback to default Ubuntu packages
          UBUNTU_VERSION=$(lsb_release -rs)
          if [ "$UBUNTU_VERSION" = "24.04" ]; then
            # Try Ubuntu 22.04 repository first
            echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_22.04/ /" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
            curl -fsSL https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/xUbuntu_22.04/Release.key | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/kubic-libcontainers.gpg > /dev/null 2>&1 || {
              echo "Kubic repository failed, using default Ubuntu packages..."
              sudo rm -f /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
              sudo rm -f /etc/apt/trusted.gpg.d/kubic-libcontainers.gpg
            }
          else
            echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_$UBUNTU_VERSION/ /" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
            curl -fsSL https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/xUbuntu_$UBUNTU_VERSION/Release.key | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/kubic-libcontainers.gpg > /dev/null
          fi

          sudo apt-get update
          sudo apt-get install -y podman

          # Verify Podman version
          podman --version
          echo "‚úÖ Podman installation completed"

      - name: Install Ansible and dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade ansible molecule molecule-plugins[podman]
          ansible-galaxy collection install \
            -r ansible-content/collections/requirements.yml \
            --force --ignore-certs

      - name: Test Podman molecule configuration
        run: |
          echo "Testing Podman-specific molecule configuration..."
          cd tests/molecule-tests
          molecule test --scenario-name podman-test

      - name: Test container image with Podman
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          echo "Testing pre-built container with Podman..."
          # Test with latest available image
          IMAGE_TAG="ghcr.io/${{ github.repository }}:latest"

          echo "Pulling image with Podman..."
          podman pull "$IMAGE_TAG" || echo "Image not available yet, will be tested in build workflow"

          if podman images | grep -q "$IMAGE_TAG"; then
            echo "Testing container execution with Podman..."
            podman run --rm "$IMAGE_TAG" syntax-check
            echo "‚úÖ Podman container test completed successfully"
          else
            echo "‚ÑπÔ∏è  Container image not available for testing (will be built later)"
          fi

  call-container-build:
    name: Build Container Image
    needs: [lint-and-syntax, unit-tests, integration-tests, security-scan, mock-device-tests]
    # Also include conditional dependencies if they ran
    if: |
      github.event_name == 'push' && github.ref == 'refs/heads/main' &&
      (always() && !failure() && !cancelled())
    uses: ./.github/workflows/build-container.yml
    with:
      push_image: true
      platforms: 'linux/amd64,linux/arm64'
    secrets: inherit
